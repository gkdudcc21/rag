{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b7d7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import Docx2txtLoader\n",
    "\n",
    "\n",
    "## 1. 문서 내용 읽기고 분할 #################################################\n",
    "loader = Docx2txtLoader('law_1.docx')\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500,\n",
    "    chunk_overlap=200,\n",
    ")\n",
    "\n",
    "document_list = loader.load_and_split(text_splitter=text_splitter)\n",
    "\n",
    "## 2. 임베딩 -> 백터 데이터베이스에 저장 ####################################\n",
    "## 2.1. 환경변수 읽어오기\n",
    "load_dotenv()\n",
    "\n",
    "## 2.2. 임베딩 모델 지정  \n",
    "embedding = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "## 로컬에 저장된 임베딩 데이터 가져오기\n",
    "database = Chroma(\n",
    "    collection_name='chroma-law',\n",
    "    persist_directory='./chroma',\n",
    "    embedding_function=embedding,\n",
    ")\n",
    "\n",
    "## 3. 질문이 있으면, 벡터 데이터베이스에서 유사도 검색 ######################\n",
    "# 3.1. 사용자 질문\n",
    "# query = '전세사기피해자 금융지원에 대해 설명해주세요.'\n",
    "query = '전세사기피해자로 인정받기 위한 조건은?'\n",
    "\n",
    "## 3.2. 벡터 데이터베이스에서 유사도 검색\n",
    "retrieved_docs = database.similarity_search(query=query, k=3)\n",
    "\n",
    "## 4. 유사도 검색으로 가져온 문서를 LLM에 질문과 같이 전달 ###################\n",
    "## 4.1. 프롬프트 작성  \n",
    "prompt = '''\n",
    "[identity]\n",
    "- 당신은 전세사기피해 법률 전문가입니다.\n",
    "-[context]를 참고하여 사용자의 질문에 답변해주세요.\n",
    "\n",
    "[context]\n",
    "{retrieved_docs}\n",
    "\n",
    "Question : {query}\n",
    "'''\n",
    "\n",
    "## 4.2. 프롬프트 변수에 값 설정\n",
    "formatted_prompt = prompt.format(retrieved_docs=retrieved_docs, query=query)\n",
    "\n",
    "## 4.3. LLM 모델 생성(ChatOpenAI 인스턴스 생성)\n",
    "llm = ChatOpenAI(model='gpt-4o')\n",
    "\n",
    "## 4.4. LLM 모델에 질문과 검색된 문서를 보냄  \n",
    "ai_message = llm.invoke(formatted_prompt)\n",
    "ai_message"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
