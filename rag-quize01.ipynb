{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ad38d03",
   "metadata": {},
   "source": [
    "# [문제]\n",
    "- law_2.docx 파일을 읽고, Chroma 저장\n",
    "- LLM 질문 -> 질문\n",
    "- 전세사기피해에 관한 법률 질문만 받기\n",
    "- 이 외의 질문은 '답변을 할 수 없습니다.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15a332d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import Docx2txtLoader\n",
    "\n",
    "loader = Docx2txtLoader('law_2.docx')\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500,\n",
    "    chunk_overlap=200,\n",
    ")\n",
    "\n",
    "document_list = loader.load_and_split(text_splitter=text_splitter)\n",
    "load_dotenv()\n",
    "\n",
    "embedding = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "database = Chroma(\n",
    "    collection_name='chroma-law2',\n",
    "    persist_directory='./chroma2',\n",
    "    embedding_function=embedding,\n",
    ")\n",
    "\n",
    "prompt = '''\n",
    "[identity]\n",
    "- 당신은 전세사기피해 법률 전문가입니다.\n",
    "-[context]를 참고하여 사용자의 질문에 답변해주세요.\n",
    "\n",
    "[context]\n",
    "{retrieved_docs}\n",
    "\n",
    "Question : {query}\n",
    "'''\n",
    "\n",
    "keywords = [\"전세사기\", \"보증금\", \"임대차\", \"피해자\", \"전세보증금\", \"보호\", \"경매\", \"확정일자\"]\n",
    "\n",
    "query = input(\"질문을 입력하세요 ▶ \")\n",
    "\n",
    "if not any(keyword in query for keyword in keywords):\n",
    "    print(\"죄송합니다. 답변을 드릴 수 없습니다.\")\n",
    "else:\n",
    "    retrieved_docs = database.similarity_search(query=query, k=3)\n",
    "\n",
    "    formatted_prompt = prompt.format(\n",
    "        retrieved_docs=retrieved_docs,\n",
    "        query=query\n",
    "    )\n",
    "\n",
    "    llm = ChatOpenAI(model='gpt-4o')\n",
    "    ai_message = llm.invoke(formatted_prompt)\n",
    "    print(ai_message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
