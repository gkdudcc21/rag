{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "897b3a85",
   "metadata": {},
   "source": [
    "## íŒŒì¸ì½˜ ë°±í„° DB ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5eb40925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pinecone 6.0.2 does not provide the extra 'async'\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU docx2txt langchain_community langchain-text-splitters langchain-chroma langchain-pinecone  pinecone pinecone "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "faa0d9ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ì „ì„¸ì‚¬ê¸°í”¼í•´ì£¼íƒì˜ ê°€ê²©ì„ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•˜ë ¤ë©´ ì—¬ëŸ¬ ìš”ì†Œê°€ ê³ ë ¤ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. ì „ì„¸ì‚¬ê¸°í”¼í•´ì£¼íƒì˜ ê°€ê²©ì€ ì£¼íƒì˜ ìœ„ì¹˜, ë©´ì , ìƒíƒœ, ì‹œê°€ í‘œì¤€ì•¡ ë“± ë‹¤ì–‘í•œ ìš”ì†Œì— ë”°ë¼ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ì™€ ê´€ë ¨ëœ êµ¬ì²´ì ì¸ ì‚¬í•­ì€ ê°ì •í‰ê°€ë²•ì¸ë“±ì˜ ê°ì • í‰ê°€ ë° í•´ë‹¹ ë²•ë ¹ì— ë”°ë¼ ì‚°ì •ë©ë‹ˆë‹¤. ì •í™•í•œ í‰ê°€ë¥¼ ìœ„í•´ì„œëŠ” ì „ë¬¸ ê°ì •í‰ê°€ì‚¬ì™€ ìƒë‹´í•˜ì‹œê¸°ë¥¼ ê¶Œì¥ë“œë¦½ë‹ˆë‹¤.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import Docx2txtLoader\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from pinecone import Pinecone\n",
    "\n",
    "\n",
    "## 1. ë¬¸ì„œ ë‚´ìš© ì½ê³  ë¶„í•  #############################################\n",
    "loader = Docx2txtLoader('law_2.docx')\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500,\n",
    "    chunk_overlap=200,\n",
    ")\n",
    "\n",
    "document_list = loader.load_and_split(text_splitter=text_splitter)\n",
    "\n",
    "## 2. ì„ë² ë”© -> ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ ###############################\n",
    "## 2.1. í™˜ê²½ë³€ìˆ˜ ì½ì–´ì˜¤ê¸°\n",
    "load_dotenv()\n",
    "\n",
    "## 2.2. ì„ë² ë”© ëª¨ë¸ ì§€ì •\n",
    "embedding = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "## 2.3 ì €ì¥ëœ íŒŒì´ì½˜ ì¸ë±ìŠ¤ ì½ì–´ì˜¤ê¸°\n",
    "# (cf) ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥\n",
    "# database = PineconeVectorStore.from_documents(\n",
    "#     documents=document_list,\n",
    "#     embedding=embedding,\n",
    "#     index_name='law02-index',\n",
    "# )\n",
    "\n",
    "api_key = os.getenv('PINECONE_API_KEY')\n",
    "pc = Pinecone(api_key=api_key)\n",
    "\n",
    "database = PineconeVectorStore(\n",
    "    index=pc.Index('law02-index'),\n",
    "    embedding=embedding\n",
    ")\n",
    "\n",
    "## 3. ì§ˆë¬¸ -> ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤(vector store)ì—ì„œ ìœ ì‚¬ë„ ê²€ìƒ‰ #############\n",
    "## 3.1. ì‚¬ìš©ì ì§ˆë¬¸\n",
    "query = 'ì „ì„¸ì‚¬ê¸°í”¼í•´ì£¼íƒì˜ ê°€ê²©ì€ ì–¼ë§ˆì¸ê°€ìš”?'\n",
    "# query = 'ì „ì„¸ì‚¬ê¸°í”¼í•´ì£¼íƒ ì„ëŒ€ì¸ì˜ êµ­ì„¸ëŠ” ê³„ì‚°ì€ ì–´ë–»ê²Œ í•˜ë‚˜ìš”?'\n",
    "# query ='ì „ì„¸ì‚¬ê¸°í”¼í•´ìëŠ” ëˆ„êµ¬ì¸ê°€ìš”?'\n",
    "# query = 'ì˜¤ëŠ˜ ì ì‹¬ ë©”ë‰´ ì •í•´ì¤˜!'\n",
    "\n",
    "## 3.2. ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ìœ ì‚¬ë„ ê²€ìƒ‰\n",
    "retrieved_docs = database.similarity_search(query=query, k=2)\n",
    "\n",
    "## 3.3 ë¬¸ì„œ ê°ì²´ 2ê°œ -> í•˜ë‚˜ì˜ ë¬¸ìì—´\n",
    "context = 'ğŸ˜ƒğŸ‘Œ\\n'.join([doc.page_content for doc in retrieved_docs])\n",
    "\n",
    "## 4. ìœ ì‚¬ë„ ê²€ìƒ‰ìœ¼ë¡œ ê°€ì ¸ì˜¨ ë¬¸ì„œë¥¼ LLMì— ì§ˆë¬¸ê³¼ ê°™ì´ ì „ë‹¬ ###################\n",
    "## 4.1. í”„ë¡¬í”„íŠ¸ ì‘ì„±  \n",
    "prompt = '''\n",
    "[identity]\n",
    "- ë‹¹ì‹ ì€ ì „ì„¸ì‚¬ê¸°í”¼í•´ ë²•ë¥  ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
    "- [context]ë¥¼ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.\n",
    "- ì „ì„¸ì‚¬ê¸°í”¼í•´ ë²•ë¥  ì´ì™¸ì˜ ì§ˆë¬¸ì—ëŠ” 'ë‹µë³€ì„ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'ë¡œ ë‹µí•˜ì„¸ìš”.\n",
    "\n",
    "[context]\n",
    "{retrieved_docs}\n",
    "\n",
    "Question : {query}\n",
    "'''\n",
    "\n",
    "## 4.2. í”„ë¡¬í”„íŠ¸ ë³€ìˆ˜ì— ê°’ ì„¤ì •\n",
    "formatted_prompt = prompt.format(\n",
    "    retrieved_docs=context, \n",
    "    query=query,\n",
    "    )\n",
    "\n",
    "## 4.3. LLM ëª¨ë¸ ìƒì„±(ChatOpenAI ì¸ìŠ¤í„´ìŠ¤ ìƒì„±)\n",
    "llm = ChatOpenAI(model='gpt-4o')\n",
    "\n",
    "## 4.4. LLM ëª¨ë¸ì— ì§ˆë¬¸ê³¼ ê²€ìƒ‰ëœ ë¬¸ì„œ ë³´ë‚´ê¸°  \n",
    "ai_message = llm.invoke(formatted_prompt)\n",
    "ai_message.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
